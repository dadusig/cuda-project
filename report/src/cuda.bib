@article{Harris:metrics,
title = {{How to Implement Performance Metrics in CUDA C/C++ | NVIDIA Developer Blog}},
year = {2012},
month = nov,
rating = {0},
author = {{Mark Harris}},
date-added = {2018-12-29T01:21:19GMT},
date-modified = {2018-12-29T01:22:57GMT},
abstract = {In the first post of this series we looked at the basic elements of CUDA C/C++ by examining a CUDA C/C++ implementation of SAXPY. In this second post we discuss how to analyze the performance of this and other CUDA C/C++ codes.~We will rely on these performance measurement techniques in future posts where performance optimization {\ldots}},
url = {https://devblogs.nvidia.com/how-implement-performance-metrics-cuda-cc/},
uri = {\url{papers3://publication/uuid/B27F826F-8DB7-4643-9342-8644B8A7EDB6}}
}

@article{Harris:coal,
title = {{How to Access Global Memory Efficiently in CUDA C/C++ Kernels}},
year = {2013},
month = jan,
rating = {0},
url = {https://devblogs.nvidia.com/how-access-global-memory-efficiently-cuda-c-kernels/}
}

@article{Erik:tiled,
title = {{Matrix-Vector Multiplication Using Shared and Coalesced
Memory Access}},
year = {2012},
month = jun,
rating = {0},
url = {https://github.com/uysalere/cuda-matrix-vector-multiplication/raw/master/vmp.pdf}
}

@INPROCEEDINGS{polybench, 
author={S. Grauer-Gray and L. Xu and R. Searles and S. Ayalasomayajula and J. Cavazos}, 
booktitle={2012 Innovative Parallel Computing (InPar)}, 
title={Auto-tuning a high-level language targeted to GPU codes}, 
year={2012}, 
url={https://ieeexplore.ieee.org/abstract/document/6339595},
volume={}, 
number={}, 
pages={1-10}, 
keywords={graphics processing units;high level languages;multiprocessing systems;parallel architectures;parallel programming;program compilers;stereo image processing;autotuning;GPU codes;graphics processing unit;optimization configuration;HMPP;high-level directive-based language;source-to-source compiler;CUDA;OpenCL code;loop permutation;loop unrolling;loop tiling;convolution kernels;PolyBench suite;belief propagation;stereo vision;hybrid multicore parallel programming;Graphics processing unit;Abstracts;Programming;Nickel;Tiles;Benchmark testing;Auto-tuning;GPU;CUDA;OpenCL;Optimization;Belief Propagation}, 
doi={10.1109/InPar.2012.6339595}, 
ISSN={}, 
month={May},}